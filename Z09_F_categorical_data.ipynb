{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           workclass  age   education  education-num          occupation  \\\n",
      "0          State-gov   39   Bachelors            NaN        Adm-clerical   \n",
      "1   Self-emp-not-inc   50   Bachelors           13.0     Exec-managerial   \n",
      "2            Private   38     HS-grad            9.0   Handlers-cleaners   \n",
      "3            Private   53        11th            7.0   Handlers-cleaners   \n",
      "4            Private   28   Bachelors           13.0      Prof-specialty   \n",
      "\n",
      "   capital-gain   gender  hours-per-week  income  \n",
      "0          2174     Male              40   <=50K  \n",
      "1             0     Male              13   <=50K  \n",
      "2             0     Male              40   <=50K  \n",
      "3             0     Male              40   <=50K  \n",
      "4             0   Female              40   <=50K  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p1\\AppData\\Local\\Temp\\ipykernel_49584\\2014181157.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['education-num'][0]=None\n"
     ]
    }
   ],
   "source": [
    "# The file has no headers naming the columns, so we pass header=None\n",
    "# and provide the column names explicitly in \"names\"\n",
    "data = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", na_values=[\" ?\"], \n",
    "    header=None, index_col=False,\n",
    "    names=['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "    'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "    'income'])\n",
    "# For illustration purposes, we only select some of the columns\n",
    "data = data[['workclass', 'age', 'education', 'education-num', 'occupation', 'capital-gain','gender', 'hours-per-week',  'income']]\n",
    "# IPython.display allows nice output formatting within the Jupyter notebook\n",
    "# add some none\n",
    "data['education-num'][0]=None\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[1:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workclass         62\n",
       "age                0\n",
       "education          0\n",
       "education-num      0\n",
       "occupation        62\n",
       "capital-gain       0\n",
       "gender             0\n",
       "hours-per-week     0\n",
       "income             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 1 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   workclass       937 non-null    object \n",
      " 1   age             999 non-null    int64  \n",
      " 2   education       999 non-null    object \n",
      " 3   education-num   999 non-null    float64\n",
      " 4   occupation      937 non-null    object \n",
      " 5   capital-gain    999 non-null    int64  \n",
      " 6   gender          999 non-null    object \n",
      " 7   hours-per-week  999 non-null    int64  \n",
      " 8   income          999 non-null    object \n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 70.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz rzućmy okiem na wszystkie atrybuty kategoryczne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Private             698\n",
       " Self-emp-not-inc     81\n",
       " Local-gov            68\n",
       " State-gov            36\n",
       " Self-emp-inc         33\n",
       " Federal-gov          21\n",
       "Name: workclass, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"workclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " HS-grad         321\n",
       " Some-college    225\n",
       " Bachelors       165\n",
       " Masters          54\n",
       " Assoc-voc        48\n",
       " 11th             46\n",
       " Assoc-acdm       35\n",
       " 10th             21\n",
       " 9th              16\n",
       " 7th-8th          15\n",
       " Doctorate        14\n",
       " 5th-6th          11\n",
       " Prof-school      10\n",
       " 12th              9\n",
       " 1st-4th           7\n",
       " Preschool         2\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"education\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Male      670\n",
       " Female    329\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Craft-repair         126\n",
       " Exec-managerial      124\n",
       " Prof-specialty       124\n",
       " Sales                112\n",
       " Other-service        107\n",
       " Adm-clerical          93\n",
       " Machine-op-inspct     61\n",
       " Transport-moving      52\n",
       " Tech-support          44\n",
       " Handlers-cleaners     43\n",
       " Farming-fishing       31\n",
       " Protective-serv       16\n",
       " Priv-house-serv        3\n",
       " Armed-Forces           1\n",
       "Name: occupation, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"occupation\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy, czy etykiety przyjmują wartości 0 lub 1.\n",
    "\n",
    "Jak nie to musimy jes troszkę przerobić."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (999, 8) y.shape: (999,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['income'], axis=1)\n",
    "y = data['income'].values\n",
    "np.unique(y)\n",
    "y[ y == ' <=50K'] = 0\n",
    "y[ y == ' >50K'] = 1\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"X.shape: {} y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podzielmy zbiór na train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz zbudujmy nasze **pipeline** preprocessingu. \n",
    "\n",
    "Wykorzystamy DataframeSelector aby wybrać określone atrybuty z DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# A class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbudujmy **pipeline** dla atrybutów numerycznych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"education-num\"])),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.],\n",
       "       [10.],\n",
       "       [12.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [14.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [12.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 2.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [12.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 6.],\n",
       "       [13.],\n",
       "       [ 7.],\n",
       "       [14.],\n",
       "       [11.],\n",
       "       [12.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [13.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 2.],\n",
       "       [ 7.],\n",
       "       [14.],\n",
       "       [ 6.],\n",
       "       [10.],\n",
       "       [ 5.],\n",
       "       [13.],\n",
       "       [11.],\n",
       "       [12.],\n",
       "       [10.],\n",
       "       [ 7.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 7.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [14.],\n",
       "       [ 5.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [15.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [ 6.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 8.],\n",
       "       [ 7.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 3.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 1.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [12.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [14.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [ 3.],\n",
       "       [ 8.],\n",
       "       [11.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 7.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [12.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [ 5.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 2.],\n",
       "       [13.],\n",
       "       [ 6.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 6.],\n",
       "       [11.],\n",
       "       [ 3.],\n",
       "       [ 9.],\n",
       "       [16.],\n",
       "       [ 7.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [15.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [14.],\n",
       "       [15.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [12.],\n",
       "       [ 4.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [ 1.],\n",
       "       [ 9.],\n",
       "       [ 6.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [12.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 5.],\n",
       "       [ 9.],\n",
       "       [16.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [16.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [11.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [14.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [12.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 7.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [15.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 4.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [11.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 5.],\n",
       "       [14.],\n",
       "       [ 7.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [12.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [16.],\n",
       "       [14.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [12.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 6.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 7.],\n",
       "       [14.],\n",
       "       [ 7.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [14.],\n",
       "       [11.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [16.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [12.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 4.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 8.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 4.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 6.],\n",
       "       [10.],\n",
       "       [11.],\n",
       "       [10.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [16.],\n",
       "       [11.],\n",
       "       [ 3.],\n",
       "       [16.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [11.],\n",
       "       [ 7.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [15.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [ 6.],\n",
       "       [11.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 7.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 4.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [12.],\n",
       "       [16.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 3.],\n",
       "       [ 8.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 6.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 6.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [12.],\n",
       "       [ 3.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [14.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 6.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 3.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [12.],\n",
       "       [10.],\n",
       "       [15.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 2.],\n",
       "       [13.],\n",
       "       [ 5.],\n",
       "       [ 4.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 6.],\n",
       "       [ 9.],\n",
       "       [12.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 6.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 2.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [16.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [16.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [16.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [11.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [ 5.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [ 9.],\n",
       "       [ 4.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [12.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [16.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 4.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [ 6.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [11.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [11.],\n",
       "       [ 9.],\n",
       "       [ 6.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [15.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [ 7.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [12.],\n",
       "       [10.],\n",
       "       [12.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [14.],\n",
       "       [12.],\n",
       "       [11.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 4.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 5.],\n",
       "       [ 9.],\n",
       "       [ 3.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 7.],\n",
       "       [10.],\n",
       "       [ 5.],\n",
       "       [10.],\n",
       "       [12.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [14.],\n",
       "       [10.],\n",
       "       [12.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [ 9.],\n",
       "       [ 5.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [10.],\n",
       "       [13.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [ 7.],\n",
       "       [ 5.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Będziemy także potrzebować imputera do kategorycznych kolumn napisowych (zwykły Imputer nie działa na tych kolumnach):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired from stackoverflow.com/questions/25239958\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz możemy zbudować pipeline dla atrybutów kategorycznych.\n",
    "\n",
    "We can convert each categorical value to a one-hot vector using a OneHotEncoder. Right now this class can only handle integer categorical inputs, but in Scikit-Learn 0.20 it will also handle string categorical inputs (see PR https://github.com/scikit-learn/scikit-learn/issues/10521). So for now we import it from future_encoders.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from future_encoders import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"workclass\", \"education\", \"occupation\", \"gender\"])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown = 'ignore')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na koniec połączmy powyższe podejścia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Robimy StratifiedKFold i znajdujemy optymalne parametry dla\n",
    "\n",
    "* SVM z jądrem rbf\n",
    "* SVM z jądrem poly\n",
    "* SVM liniowego\n",
    "* Regresji logistycznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline), \n",
    "    ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_1 = GridSearchCV(pipe, param_grid, cv=kfold)\n",
    "\n",
    "grid_1.fit(X_train, y_train)\n",
    "grid_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('preprocessing', preprocess_pipeline), \n",
    "#     ('classifier', SVC(kernel='poly'))])\n",
    "\n",
    "# param_grid = {\n",
    "#             'classifier__gamma': [0.001, 0.01, 0.1,1,10,100],\n",
    "#             'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "#             'classifier__degree': [1,2,3,4],\n",
    "#             'classifier__coef0': [0.1, 0.01, 0.01]\n",
    "# }\n",
    "\n",
    "# grid_3 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "# grid_3.fit(X_train, y_train)\n",
    "# grid_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 100, 'classifier__gamma': 0.01}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2 = Pipeline([('preprocessing', preprocess_pipeline), ('classifier', SVC(kernel='rbf'))])\n",
    "\n",
    "param_grid2 = {\n",
    "            'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_2 = GridSearchCV(pipe2, param_grid2, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_2.fit(X_train, y_train)\n",
    "grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.76720912        nan 0.79471698        nan 0.78470912\n",
      "        nan 0.79471698        nan 0.8034827         nan 0.79471698\n",
      "        nan 0.80721698        nan 0.79471698        nan 0.79470912\n",
      "        nan 0.79471698        nan 0.79345912        nan 0.79471698]\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.76720902        nan 0.81633118        nan 0.79192635\n",
      "        nan 0.81633118        nan 0.81163732        nan 0.81633118\n",
      "        nan 0.81633118        nan 0.81633118        nan 0.81507923\n",
      "        nan 0.81633118        nan 0.81601819        nan 0.81633118]\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 1, 'classifier__penalty': 'l2'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "pipe4 = Pipeline([('preprocessing', preprocess_pipeline), ('classifier', LogisticRegression())])\n",
    "\n",
    "param_grid4 = {\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none']\n",
    "}\n",
    "\n",
    "grid_4 = GridSearchCV(pipe4, param_grid4, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_4.fit(X_train, y_train)\n",
    "grid_4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM linear\n",
      "precision_score: 0.6\n",
      "recall_score: 0.1956521739130435\n",
      "f1_score: 0.29508196721311475\n",
      "accuracy_score: 0.785\n",
      "rbm\n",
      "precision_score: 0.75\n",
      "recall_score: 0.2608695652173913\n",
      "f1_score: 0.3870967741935483\n",
      "accuracy_score: 0.81\n",
      "logistic\n",
      "precision_score: 0.7142857142857143\n",
      "recall_score: 0.32608695652173914\n",
      "f1_score: 0.4477611940298507\n",
      "accuracy_score: 0.815\n"
     ]
    }
   ],
   "source": [
    "from sklearn import  metrics\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('SVM linear', grid_1.best_estimator_))\n",
    "models.append(('rbm', grid_2.best_estimator_))\n",
    "models.append(('logistic', grid_4.best_estimator_))\n",
    "\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"precision_score: {}\".format(metrics.precision_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
    "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test)))\n",
    "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test)))\n",
    "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test)))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.295082</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Method  precision_score  recall_score  f1_score  accuracy_score\n",
       "0  logistic         0.600000      0.195652  0.295082           0.785\n",
       "1  logistic         0.750000      0.260870  0.387097           0.810\n",
       "2  logistic         0.714286      0.326087  0.447761           0.815"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'precision_score': precision_score, \n",
    "     'recall_score': recall_score, \n",
    "     'f1_score': f1_score,\n",
    "     'accuracy_score' : accuracy_score\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "df.insert(loc=0, column='Method', value=name)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
