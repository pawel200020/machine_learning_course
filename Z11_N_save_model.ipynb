{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p1\\AppData\\Local\\Temp\\ipykernel_23776\\357239312.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
      "C:\\Users\\p1\\AppData\\Local\\Temp\\ipykernel_23776\\357239312.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "ZrÃ³bmy szybki preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4200      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "history = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_model = ModelCheckpoint(\"wagi_best.h5py\",save_best_only=True)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/943 [============================>.] - ETA: 0s - loss: 0.4581 - accuracy: 0.7841INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.4578 - accuracy: 0.7841 - val_loss: 0.3920 - val_accuracy: 0.8074\n",
      "Epoch 2/100\n",
      "937/943 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8122INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3815 - accuracy: 0.8118 - val_loss: 0.3780 - val_accuracy: 0.7997\n",
      "Epoch 3/100\n",
      "936/943 [============================>.] - ETA: 0s - loss: 0.3766 - accuracy: 0.8109INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3764 - accuracy: 0.8111 - val_loss: 0.3699 - val_accuracy: 0.8138\n",
      "Epoch 4/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3739 - accuracy: 0.8111 - val_loss: 0.4005 - val_accuracy: 0.8027\n",
      "Epoch 5/100\n",
      "913/943 [============================>.] - ETA: 0s - loss: 0.3699 - accuracy: 0.8150INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3702 - accuracy: 0.8146 - val_loss: 0.3679 - val_accuracy: 0.8122\n",
      "Epoch 6/100\n",
      "912/943 [============================>.] - ETA: 0s - loss: 0.3639 - accuracy: 0.8238INFO:tensorflow:Assets written to: wagi_best.h5py\\assets\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3637 - accuracy: 0.8240 - val_loss: 0.3568 - val_accuracy: 0.8242\n",
      "Epoch 7/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3693 - accuracy: 0.8153 - val_loss: 0.3677 - val_accuracy: 0.8133\n",
      "Epoch 8/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3689 - accuracy: 0.8141 - val_loss: 0.3644 - val_accuracy: 0.8212\n",
      "Epoch 9/100\n",
      "943/943 [==============================] - 1s 2ms/step - loss: 0.3668 - accuracy: 0.8165 - val_loss: 0.3676 - val_accuracy: 0.8193\n",
      "Epoch 10/100\n",
      "943/943 [==============================] - 1s 2ms/step - loss: 0.3674 - accuracy: 0.8163 - val_loss: 0.3640 - val_accuracy: 0.8176\n",
      "Epoch 11/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3664 - accuracy: 0.8152 - val_loss: 0.4080 - val_accuracy: 0.7807\n",
      "Epoch 12/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3668 - accuracy: 0.8140 - val_loss: 0.3697 - val_accuracy: 0.8098\n",
      "Epoch 13/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3657 - accuracy: 0.8163 - val_loss: 0.3659 - val_accuracy: 0.8189\n",
      "Epoch 14/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3678 - accuracy: 0.8146 - val_loss: 0.3669 - val_accuracy: 0.8152\n",
      "Epoch 15/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3645 - accuracy: 0.8156 - val_loss: 0.3624 - val_accuracy: 0.8171\n",
      "Epoch 16/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3655 - accuracy: 0.8125 - val_loss: 0.3677 - val_accuracy: 0.8172\n",
      "Epoch 17/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3654 - accuracy: 0.8158 - val_loss: 0.3744 - val_accuracy: 0.8131\n",
      "Epoch 18/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3649 - accuracy: 0.8145 - val_loss: 0.3623 - val_accuracy: 0.8168\n",
      "Epoch 19/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3645 - accuracy: 0.8144 - val_loss: 0.3686 - val_accuracy: 0.8156\n",
      "Epoch 20/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3652 - accuracy: 0.8142 - val_loss: 0.3656 - val_accuracy: 0.8185\n",
      "Epoch 21/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3654 - accuracy: 0.8137 - val_loss: 0.3634 - val_accuracy: 0.8148\n",
      "Epoch 22/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3653 - accuracy: 0.8151 - val_loss: 0.3641 - val_accuracy: 0.8159\n",
      "Epoch 23/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3636 - accuracy: 0.8178 - val_loss: 0.3627 - val_accuracy: 0.8178\n",
      "Epoch 24/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3622 - accuracy: 0.8173 - val_loss: 0.3614 - val_accuracy: 0.8177\n",
      "Epoch 25/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3633 - accuracy: 0.8180 - val_loss: 0.3685 - val_accuracy: 0.8186\n",
      "Epoch 26/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3631 - accuracy: 0.8150 - val_loss: 0.3617 - val_accuracy: 0.8179\n",
      "Epoch 27/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3626 - accuracy: 0.8176 - val_loss: 0.3645 - val_accuracy: 0.8173\n",
      "Epoch 28/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3624 - accuracy: 0.8152 - val_loss: 0.3958 - val_accuracy: 0.7903\n",
      "Epoch 29/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3635 - accuracy: 0.8155 - val_loss: 0.3634 - val_accuracy: 0.8179\n",
      "Epoch 30/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3610 - accuracy: 0.8178 - val_loss: 0.3714 - val_accuracy: 0.8067\n",
      "Epoch 31/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3622 - accuracy: 0.8161 - val_loss: 0.3614 - val_accuracy: 0.8170\n",
      "Epoch 32/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3612 - accuracy: 0.8185 - val_loss: 0.3614 - val_accuracy: 0.8173\n",
      "Epoch 33/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3615 - accuracy: 0.8170 - val_loss: 0.3625 - val_accuracy: 0.8156\n",
      "Epoch 34/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3610 - accuracy: 0.8188 - val_loss: 0.3649 - val_accuracy: 0.8157\n",
      "Epoch 35/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3598 - accuracy: 0.8170 - val_loss: 0.3609 - val_accuracy: 0.8172\n",
      "Epoch 36/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3600 - accuracy: 0.8180 - val_loss: 0.3657 - val_accuracy: 0.8189\n",
      "Epoch 37/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3709 - accuracy: 0.8162 - val_loss: 0.3753 - val_accuracy: 0.8124\n",
      "Epoch 38/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3631 - accuracy: 0.8163 - val_loss: 0.3633 - val_accuracy: 0.8185\n",
      "Epoch 39/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3617 - accuracy: 0.8184 - val_loss: 0.3638 - val_accuracy: 0.8159\n",
      "Epoch 40/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3627 - accuracy: 0.8173 - val_loss: 0.3630 - val_accuracy: 0.8178\n",
      "Epoch 41/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3627 - accuracy: 0.8187 - val_loss: 0.3789 - val_accuracy: 0.8144\n",
      "Epoch 42/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3637 - accuracy: 0.8170 - val_loss: 0.3646 - val_accuracy: 0.8150\n",
      "Epoch 43/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3653 - accuracy: 0.8138 - val_loss: 0.3679 - val_accuracy: 0.8170\n",
      "Epoch 44/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3648 - accuracy: 0.8154 - val_loss: 0.3698 - val_accuracy: 0.8135\n",
      "Epoch 45/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3632 - accuracy: 0.8167 - val_loss: 0.3682 - val_accuracy: 0.8122\n",
      "Epoch 46/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3629 - accuracy: 0.8165 - val_loss: 0.3637 - val_accuracy: 0.8159\n",
      "Epoch 47/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3614 - accuracy: 0.8181 - val_loss: 0.3666 - val_accuracy: 0.8141\n",
      "Epoch 48/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3653 - accuracy: 0.8148 - val_loss: 0.3684 - val_accuracy: 0.8166\n",
      "Epoch 49/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3642 - accuracy: 0.8166 - val_loss: 0.3684 - val_accuracy: 0.8125\n",
      "Epoch 50/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3623 - accuracy: 0.8179 - val_loss: 0.3694 - val_accuracy: 0.8133\n",
      "Epoch 51/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3632 - accuracy: 0.8161 - val_loss: 0.3777 - val_accuracy: 0.8034\n",
      "Epoch 52/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3633 - accuracy: 0.8159 - val_loss: 0.3673 - val_accuracy: 0.8141\n",
      "Epoch 53/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3606 - accuracy: 0.8165 - val_loss: 0.3892 - val_accuracy: 0.8006\n",
      "Epoch 54/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3611 - accuracy: 0.8188 - val_loss: 0.3641 - val_accuracy: 0.8187\n",
      "Epoch 55/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3609 - accuracy: 0.8185 - val_loss: 0.3628 - val_accuracy: 0.8169\n",
      "Epoch 56/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3595 - accuracy: 0.8194 - val_loss: 0.3661 - val_accuracy: 0.8148\n",
      "Epoch 57/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3591 - accuracy: 0.8169 - val_loss: 0.3637 - val_accuracy: 0.8179\n",
      "Epoch 58/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3620 - accuracy: 0.8178 - val_loss: 0.3669 - val_accuracy: 0.8178\n",
      "Epoch 59/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3626 - accuracy: 0.8155 - val_loss: 0.3667 - val_accuracy: 0.8141\n",
      "Epoch 60/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3615 - accuracy: 0.8176 - val_loss: 0.3644 - val_accuracy: 0.8185\n",
      "Epoch 61/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3629 - accuracy: 0.8180 - val_loss: 0.3656 - val_accuracy: 0.8158\n",
      "Epoch 62/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3625 - accuracy: 0.8155 - val_loss: 0.3648 - val_accuracy: 0.8183\n",
      "Epoch 63/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3612 - accuracy: 0.8144 - val_loss: 0.3648 - val_accuracy: 0.8143\n",
      "Epoch 64/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3613 - accuracy: 0.8178 - val_loss: 0.3671 - val_accuracy: 0.8142\n",
      "Epoch 65/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3608 - accuracy: 0.8178 - val_loss: 0.3640 - val_accuracy: 0.8171\n",
      "Epoch 66/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3604 - accuracy: 0.8161 - val_loss: 0.3674 - val_accuracy: 0.8177\n",
      "Epoch 67/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3592 - accuracy: 0.8169 - val_loss: 0.3640 - val_accuracy: 0.8159\n",
      "Epoch 68/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3593 - accuracy: 0.8178 - val_loss: 0.3788 - val_accuracy: 0.8019\n",
      "Epoch 69/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3589 - accuracy: 0.8177 - val_loss: 0.3885 - val_accuracy: 0.7974\n",
      "Epoch 70/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3583 - accuracy: 0.8191 - val_loss: 0.3639 - val_accuracy: 0.8183\n",
      "Epoch 71/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3584 - accuracy: 0.8171 - val_loss: 0.3630 - val_accuracy: 0.8189\n",
      "Epoch 72/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3580 - accuracy: 0.8193 - val_loss: 0.3682 - val_accuracy: 0.8124\n",
      "Epoch 73/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3579 - accuracy: 0.8175 - val_loss: 0.3653 - val_accuracy: 0.8145\n",
      "Epoch 74/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3587 - accuracy: 0.8200 - val_loss: 0.3679 - val_accuracy: 0.8173\n",
      "Epoch 75/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3582 - accuracy: 0.8174 - val_loss: 0.3638 - val_accuracy: 0.8162\n",
      "Epoch 76/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3580 - accuracy: 0.8177 - val_loss: 0.3635 - val_accuracy: 0.8166\n",
      "Epoch 77/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3570 - accuracy: 0.8195 - val_loss: 0.3637 - val_accuracy: 0.8177\n",
      "Epoch 78/100\n",
      "943/943 [==============================] - 1s 2ms/step - loss: 0.3584 - accuracy: 0.8180 - val_loss: 0.3629 - val_accuracy: 0.8173\n",
      "Epoch 79/100\n",
      "943/943 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8191 - val_loss: 0.3626 - val_accuracy: 0.8173\n",
      "Epoch 80/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3571 - accuracy: 0.8201 - val_loss: 0.3641 - val_accuracy: 0.8183\n",
      "Epoch 81/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3574 - accuracy: 0.8177 - val_loss: 0.3622 - val_accuracy: 0.8173\n",
      "Epoch 82/100\n",
      "943/943 [==============================] - 1s 2ms/step - loss: 0.3561 - accuracy: 0.8194 - val_loss: 0.3648 - val_accuracy: 0.8171\n",
      "Epoch 83/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3568 - accuracy: 0.8188 - val_loss: 0.3631 - val_accuracy: 0.8169\n",
      "Epoch 84/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3559 - accuracy: 0.8194 - val_loss: 0.3626 - val_accuracy: 0.8178\n",
      "Epoch 85/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3565 - accuracy: 0.8181 - val_loss: 0.3626 - val_accuracy: 0.8177\n",
      "Epoch 86/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3574 - accuracy: 0.8179 - val_loss: 0.3627 - val_accuracy: 0.8175\n",
      "Epoch 87/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3564 - accuracy: 0.8184 - val_loss: 0.3625 - val_accuracy: 0.8177\n",
      "Epoch 88/100\n",
      "943/943 [==============================] - 1s 2ms/step - loss: 0.3562 - accuracy: 0.8181 - val_loss: 0.3650 - val_accuracy: 0.8174\n",
      "Epoch 89/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3560 - accuracy: 0.8192 - val_loss: 0.3655 - val_accuracy: 0.8145\n",
      "Epoch 90/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3561 - accuracy: 0.8187 - val_loss: 0.3645 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3558 - accuracy: 0.8202 - val_loss: 0.3712 - val_accuracy: 0.8077\n",
      "Epoch 92/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3567 - accuracy: 0.8179 - val_loss: 0.3666 - val_accuracy: 0.8167\n",
      "Epoch 93/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3562 - accuracy: 0.8196 - val_loss: 0.3715 - val_accuracy: 0.8090\n",
      "Epoch 94/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3555 - accuracy: 0.8189 - val_loss: 0.3623 - val_accuracy: 0.8174\n",
      "Epoch 95/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3551 - accuracy: 0.8204 - val_loss: 0.3675 - val_accuracy: 0.8129\n",
      "Epoch 96/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3556 - accuracy: 0.8187 - val_loss: 0.3676 - val_accuracy: 0.8151\n",
      "Epoch 97/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3550 - accuracy: 0.8211 - val_loss: 0.3800 - val_accuracy: 0.8035\n",
      "Epoch 98/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3551 - accuracy: 0.8184 - val_loss: 0.3648 - val_accuracy: 0.8169\n",
      "Epoch 99/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3557 - accuracy: 0.8202 - val_loss: 0.3640 - val_accuracy: 0.8153\n",
      "Epoch 100/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3557 - accuracy: 0.8179 - val_loss: 0.3664 - val_accuracy: 0.8148\n"
     ]
    }
   ],
   "source": [
    "save_best_model = ModelCheckpoint(\"wagi_best.h5py\",save_best_only=True)\n",
    "history = model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[save_best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABIRElEQVR4nO3dd5wV9b3/8df39O2NZZelI8giICLYG7aouZZoRGMSE0nUmESNJcUYY4wlMZqYot4katQY41WjMeEXjRUIsYuKgDQBYdmFZXs9e9rM9/fHWdalL3BgAN/Px+M8ds/MnJnP+Z458552Zoy1FhEREfGOz+sCREREPu0UxiIiIh5TGIuIiHhMYSwiIuIxhbGIiIjHFMYiIiIe22YYG2MeNMbUGWMWbKG/Mcb8zhizzBgzzxhzcObLFBER2Xf1Zcv4YeDUrfQ/DRjV/bgU+P3OlyUiIvLpsc0wttbOBpq2MshZwCM27U2g0BgzIFMFioiI7Osyccx4ILC61/Pq7m4iIiLSB4HdOTFjzKWkd2WTlZU1afDgwRkbt+u6+Hw6H21nqR0zQ+2YGWrHzFA7ZsbOtuPSpUsbrLWlm+uXiTCuAXqn6qDubpuw1t4H3AcwefJkO2fOnAxMPm3WrFlMmTIlY+P7tFI7ZobaMTPUjpmhdsyMnW1HY8yqLfXLxKrSdOAr3WdVHw60WmvXZmC8IiIinwrb3DI2xvwfMAXoZ4ypBn4CBAGstX8AngM+CywDosC0XVWsiIjIvmibYWytvWAb/S3w7YxVJCIi8imjI/oiIiIeUxiLiIh4TGEsIiLiMYWxiIiIxxTGIiIiHlMYi4iIeExhLCIi4jGFsYiIiMcUxiIiIh5TGIuIiHhMYSwiIuIxhbGIiIjHFMYiIiIeUxiLiIh4TGEsIiLiMYWxiIiIxxTGIiIiHlMYi4iIeExhLCIi4jGFsYiIiMcUxiIiIh5TGIuIiHhMYSwiIuIxhbGIiIjHFMYiIiIeUxiLiIh4TGEsIiLiMYWxiIiIxxTGIiIiHlMYi4iIeExhLCIi4jGFsYiIiMcUxiIiIh5TGIuIiHhMYSwiIuIxhbGIiIjHFMYiIiIeUxiLiIh4TGEsIiLiMYWxiIiIxxTGIiIiHlMYi4iIeExhvBnx16ez4pgDqT7nKFKrFmx2GDceJ1lXh3Xd3VydiIhst64WSHZ5XcUWBbwuYI8Sa6X9t5ez5i9vY/yGRGMjH5/9eSq+cQo5026HUDZuIkHL40/Q8Mc/4jQ2YoJBAhUDCA0cSKCigmD5AIIDygmUlxOprCRQUtKnSaeammidPp3QoEFkTZpEoKhok2FsIoGbSIC16Qfgy83F+LZ/nSpVX09s8WKcllayJh5EcOBAjDFbHN66LqnVy0gtfR8LmGAWhLIgEMZtb8FtbsRpacJtb8Hk9MPXfyi+3Fx82dmYSBa+SBgTDuNz2gmUD8Dk9YfNTM/t6sJpaydY1h9cF9rXQLQJ8isguwSMwaZS2EQC27QK1i2Gthp8pQMx+RWQVw7ZxdBRB62roWU1tK+FrCIoGAyFg3GDxSTXrCW5egWp6iqStWsJj9qPvNPOwuSXb1CXdV2ib71FqqGB8LAhhAoNvs5qiLdBVhGuP5dUaxLXsYRLI5iuBuhYx+CqeTCvDvIHQsGgdP3+4CfjtXar7b1FsVZoWwNtNRAphPLxEAhv5YNOQLQBOuvT/69vI5+/b9NLdkHjMmzdEtpeeAXrOAT7FRDsV0igpBCfSaRrirVCrA1y+kHpaGzRKOKtQZyuJCS7MKkopKIEygcQHHsEJhjZYDI2kSD6xn9IrlhMeHAZ4UH98AUsRU3zoXUkjq+AxIoVpBoaiIwbn54/Nqk1BnULIRXv+Qyta3FtNm6gADfp4nZ14c/LI1hejgmFPnldvC1df7w13U7G1/0w6TborIOOOpy61XTMW50enz8f12Tjyy2k4MgxBGwDNC1Pz2+5ZenPvWBQer5tXgUNS6F+Mc6aFZjCAfgGjYP+Y6C0EoJZ4KbSDycJHetw65fjrl2BU7sKaw0mvz+moDw9jwaCEG9JB0xXM7ajBbe1Gae1Bbe9HeuAr/8g/AP2w1exPwW1raReq4LOdZiOWkysCYJhTCgLwtngD+NGO3Db23E7OnGjUWwwF5NTBNnphwllQSCICYQwgSDWSUC8C5vogngUDJhQuHu8YQI5AXw2mv7+djWBk4BAJP0IZoHrpNuqvTb9NxmF4hHQb3/oNyr93emoS8/rrdXpedgfglBuelnsBDCpFkxHbXocHXUQyU9/z/MHQv6A9LQbl6XbvrM+/ZkWj4D+B0DZ2PR3p2V197KiKr1cLRkJJfulaygZBYMPgx1Yxm4vY7sX6rvb5MmT7Zw5czI2vlmzZjFlypQt9nfa2vDn52++Z2cDdsmLNPzyZhreM0QGFzLo/kdw6mqoueZqEg1dlEw0hMYeTv2/PyTV2E72gfuTd+gBpFavILl2LYm6FpJtSZzoJ6P1hQ37fXMEgZJ+6QVnVlF6YZVTmv6ChnKxjStomf48df94F7fL6XlteEAhWZVDcGNxknXNJBvaSLXGNindX1xMzsEHkLNfPjn92iEZI7rWEl3VQfSjOpyOGP78HPx5Ofjzc7Aph9jHa3Ca2zYYT6C0hOyDxlEXDjKoMAenqR6npQmnqYVkfRPJlgTW2WTyOyRvUBeDTqb7S7d/uj2cBDhJVt//Jp1LG+h/dBZFg2owzidrso6NUDe/lJZFDmw02xqfJZDlEMx2CGS5YLoHsGCtwYn7SHX5SHX5cVOb/2IFs1MUVSYonNgPG8yl9cMozfOiJFt77f0wllBuCn/Ikuz0k4p9Emq+gEukOElWvwSRwiTWNbiOwaYMTspP0ikhGcsm0eqQaukkPLSC7FEDyB6aR1a5j0CgPR3mnemHdR3irQGitX661hlwEwQjMYI5DsEcBzdliLdHiMdLSLQFMaEQOcNzyalwySpoxtdVmw5Jetbd0hll/OlQzi1LL9z8Aazxk2xJEconvVBMdqXDqa0GsNR9kEfjorxN2iyQ5RDKcwgW+gkVhki1RulqMMSbg1h38ysbgSyH7IFBskeVYcJhOhasoXNVHDfZe3hLKM8hkOWQaA+Q6tpw5SE0oJCccfuRPXY/fLEaaFiCaVqOdVIk2gLEmoPEWoLEWwNgt1BHtiWYnaJgWCdFI6ObHaY368KqV0rpagxu2tNnyR/cRfHoKFmD8qGrCSdhSbQHSLT7ibcE0zW1Rlg/Sxu/xR9y8YfT85d1wLoG6xicpME6e/uOy/RnGC5MEin1E8jx43SlcLocnLjFH7IUH5RNoKwc8gakg7FpOW7tMhrmBehYE6FgWJSikVF8BaXp+dVJkGzppP7NJK3LfARyDXkjc8gdN4DsscMh1kZi1SoS1etINrSRMyxEZNSodLD2GwWJTlj3IamqD1nzXBuxpiCBbAjkhwkU5eHPDmCSLfiSzRhfCn9WmMI/rehZudtWzmyLMeZda+3kzfbbJ8O4sxH+c3t6oRPOpWn2x6x74nXyjzyA8otOxp8VTq+Brp0LVW+RrF5O7TuF6Q//lGMov+NufOH01obb2Unt9VfR+sKrAESKE/Q/sI2c8sQnE88bkA6VvAHYZJJka5RYdTs1T66g/5R8SsY60NWcfvRKtK7GILXvFhBrCpFdYSg7bTBuRzvR5Y1EqxN0NYbwB12CuQ7BPB/BggA+tx2wYIBQPrG6JJ1r/DjxDRdWvqBLdmmCQLaDE/f1PDAQKUwSKUoSLkriD7pEG0J01YfprAvhdIeLL+h2LygsweIsguX9CQ4dTnBYJSbgg2QMm4xDKo4vOxdfYRH+ohJ8eYXQtBK36gPc6oW4tctxTQibMwg3ewDRtdAyYx6DL55EbkkT1C+BWAv4Q3SuC1P1YhbBfEOyzZI7fgAVl5+Lv18F0TlzWHPfv0k2RSk8qIhgRTmmoAxTMAAiRaRqa0iuqSG5bh2pplbAD/4A+IOYQBB/QR6BgmwCeQECETe9dVdeTmDgYALlA+l4/W2a//ES0cXVmKAP67jgQvaQHAonlRAeXEqiK494E8TXdeB0JQj2KyRYkkuwMIzBoWtVM11Lq4mtWAXOpocvArl+gtkJQtlx/GGXWEuQrsYgdv3KgQF/to9ATgh/ToT4uk6caDL92oIQJhAg2RLbcNwGgvl+wrlduAlLtDEErsEEDKF+ubhJixNL4cYS+PNzKb9wCvmjc9JbGh114KZItnSx5tkGoqsTlBxWQOmJAzDhnPQWSNFwWha0s/aepyk871xKLppGsqaK5No16b0La9eRqK4hsaoKp6EBk5VFVuVIIkNLySr3E8gNYoM5EMzG+rNIrq4hOnc+0SU1pNq731tegNyxFeQeMp7QyP2J17YSr6ojvmotrauqKRpSQqjAIZzVij+5lq7VUTpr/UTrQlsMLH9RPpERg4gMryCQ7cPYTnxuB75UK06XQ7LTkGxziNd2ElvdQsmZh1H6pdMwkQIIhD7Z+2Td9PPcMuoefobGB//CgNtuJXdiJSa2Dl+0huTqKppeW0XrjDm40S5Cw4fjtLXiNDb1+vD9hEfuR2TMWMIjR2IdB6epAae2CqexFqzFBIP4QsH034Ii/P0H4S8diL+wAAIBbCIJ0Vbc9npwHAjlpB/+ECYYxJ+fhy8vH39eLgQC6S3c5gactctYPf89KoZXQigfa4LgOt3zuIN1HHAtvpwcfLk5+PPy8OXkpAMolcLG2iDa3P19T2GdZHrvgT+Y3sMRyoJgOL3VmYhhk0lsIkayoZn48mpiH60gWV3da+Hkw19QgNPWhgmFKP7KVyj52jR8+fm0v/Ai626/nVRtLeFhA4mvrMHfrx/9vvEN8k//H5r/8hcaH3wIHIeCcz9Pqq6eztdfx3Z1YUIhbDL5yZonYMJhym+8kcLPn9PTLVlTQ9Ull5Ksrib/f07F7YiSXFdHqq4Op7UVG4v12vOYw+heOeV5GBtjTgV+C/iBB6y1t2/UfwjwZ6Cwe5jrrLXPbW2cmQzjVGMj7959N4dcfz2+UAj+dTXMeQgbzKXhfWhYkEe4KEG8JUgo12HgkU1EilLYSBEtdSOpm1mPTbn0//73Kfrylze7+7B9xkywLrmHTcB0NUG0Mb3bsd8oiBRstq6VF3wRp6mJEf9+Lr0r2dp08HQ20Pnf/1B1/V0Eigvp/4Pvk3/GWRtON5VI71YJRNLj93cfUUh0wtp5sOZ9WPsBhPOwFZOIx/rRubAK/H6yDzmEyIghmHgzxDvSC5Seh/PJQsZ1wE2md+slu7DJLha/9z6VR5yAKSiH3P6Q3e+Tae8I101/qdfvNkwkWH76GfjCYYb/4xmMPx3+1nVZee5UnJYWRjz3LM3/9zh1d91FoLQfuUcfQ8vf/kZw8GAqbv852QcfvOP1bENs8WKan3gCXyhM4dRzCY8cud3jcKNRXn/mGQ496ihMVha+SARfVlZ6t6jrQtMKqF8EkUJsVn9ia9voWriU1Lo6nOYmUk3NOC0thIYMIfuQQ8g+9FBCgwYCYB2HVF0dyTVrMOEI4f1G4MvKSs8vbgo3aYm++y6dr71Ock0Nvuyc9OGCnBw6X32V2MKF5J1yCuU3/phASQltL7zI2htvxCaT5BxyCB3/+Q8Fn/scA265GRMMEn33XVZdNI3syZMYct99mOBmtgp7vW8TDvd8pltjrSVZVYUbjxMeNWqLu+w3u/CzFhId2NZa4ksWY7PKsL5gep4GQkOGECgt7dNnZR2H2ptuouVvT1H0xQsou+GGzR726XzzLaqmTaPgnLOpuO22zY7L6eig9Zl/0PHf2QTLyggOGUJo6FBCQ4cSHj78k93iHtjZENlZTltbeu9kQQG+nByMz0di5Urqf3c3bc89hy8/n/CIEXTNnUt49GjKf3wD2ZMnE33nHep/dzfRd95JL0OsJf+zp1F6zTWEBg0C0ufvRN96i87X38CXm0to2DBCw4fhLyhg7Q0/JvrmmxROnUrZDT8isWIFqy/9Bm48zuB77yH7kEM2qdVam16hiKVXLHofatyVYZye8FYepMN1OTACCAEfAAdsNMx9wDe7/z8AWLmt8U6aNMlmSuOfH7ELR1fapVOOt00P/M66NxZZ9/9dY2t/frtdOLrS1nzvWus2VduOmf+2S48+yi4aN97W/+ZO+/EXvmAXjq60K796kY1//HHG6lmv5Z//tAtHV9qO117boLvrunbF2efYj048yaba2zM+3Z0xc+bMXT6N1udfsAtHV9qmJ57o6dYy/f/ZhaMrbcv06T3dovPm2Y9OPMkuHF1p1/70p9bp6NjltWXK7mjH7eUmErb+93+wi8aNt0sOO9yuvvwKu3B0pV3x+XNt/OOPreu6tu7ee+3C0ZV21SWX2NjSpXbJ4UfYZaecalMtLZ7UvDva0XVdW3vHHXbh6Epbfe13rZtIbNA/2dRklx57nF12yqnW6ezc5fXsCnvi/Lhe16JFtuqyb9qlx02xjY8+at1kcoP+ruvajjfesGtvvsV2vvfedo3bTaXsul/dZReOrrTLzzzLLj54kl163BQbW7p0h2rd2XYE5tgtZe2WethPgvYI4IVez38I/HCjYf4I/KDX8K9va7yZDGPXde1r9/6vXXHeeXbh6Er70aT9bdUlX08vxG+51bqO0zNssrHRrrr0UrtwdKVdctjhtvmZZ6zruhmrpTcnFksv9K64coPu68Oo+Zlndsl0d8buWvh9fMEX7ZKjjrap9g7rxOP2o+NPsMvPPnuDz8paa1PtHbZryZJdXlOm7ckLv9jSpXbF1PPswsoxdt2v7tokfJqefNIuHHOAXTjmALv4kENtbMUKjyrdfe3ouq6t/8Mf0wvtM860dffcY6MLFljXcWzVt75tF44bb6MLFuyWWnaFPXl+3B3aXn7ZLp58iF1+xpk2sXbtDo9nV4bxNndTG2POBU611l7c/fxC4DBr7eW9hhkAvAgUATnASdbadzczrkuBSwHKysomPf7441ud9vbo6OigIlXF/s/dRPXSodjaDjr+57N0nn76pmftui6hDz8kOXw4Njc3YzVsTu7TT5P9ygwafnYbbmEhuC4lN98CQOONP94tZ+ltj46ODnJ3cZsABD7+mJJf3EHHZ0/DZmeT99TTNF/1HRKVlbt82rvD7mrHHea6+Nra0vPkZoTmzSPv6b/TfsEXPP1Mdnc7Rt56m6xZMwmuXIWxFjcnB19nJ+3nfp7oSSfttjoybY+fH3cDE41iQyEI7Phht51tx+OPP36ndlOfS/o48frnFwL3bDTMNcC19pMt44WAb2vjzeSWsbXWzpwxw9oHPmPtHSOt29VmEzU1GR3/joqvXGkXjq60dffcY621tuUf/7ALR1fa1n8/73Flm7c716Crr77GLppwkF18yKF21cWX7Lbp7g6f9i2RTPGqHZMNDbb578/Y1Vd+x6758Y2b7LHZ22h+zIxduWXcl1WEGmBwr+eDurv19nXg1O5wf8MYEwH6AXV9GH9GlDS+DavfhNN/jYnkEazY9GcYXggNHUrOUUfR8renKPn616m/517CB4wh7zMne12a50qvuYb2l1/GbW+n/3ev9bockR6BkhIKz/4chWd/zutS5FOiL/tI3wFGGWOGG2NCwBeA6RsNUwWcCGCMGQNEgPpMFrpVTooRKx5J/0B74ld222T7quiCL5CqraXm6mtIrl5N6ZVX7tCFOvY1oUEDKb/5p5T98Doio0d7XY6IiGe2uWVsrU0ZYy4HXiB9ZvWD1toPjTE3k97kng5cC9xvjLma9OUYLureJN893v8LOdFqOOPRnfsZzi6SO2UKgbIyOmbOJOugg8g97jivS9pjFH7uc16XICLiuT4ll03/Zvi5jbrd2Ov/hcBRmS1tO+x/KiuGX8iIytM9K2FrTCBA4XlTabj7HkqvumrHLoMoIiL7rD1vM3JH5A+gaui5jNiDQ67kkkvIOeJIsg+e6HUpIiKyh9GBy93EFwopiEVEZLMUxiIiIh5TGIuIiHhMYSwiIuIxhbGIiIjHFMYiIiIeUxiLiIh4TGEsIiLiMYWxiIiIxxTGIiIiHlMYi4iIeExhLCIi4jGFsYiIiMcUxiIiIh5TGIuIiHhMYSwiIuIxhbGIiIjHFMYiIiIeUxiLiIh4TGEsIiLiMYWxiIiIxxTGIiIiHlMYi4iIeExhLCIi4jGFsYiIiMcUxiIiIh5TGIuIiHhMYSwiIuIxhbGIiIjHFMYiIiIeUxiLiIh4TGEsIiLiMYWxiIiIxxTGIiIiHlMYi4iIeExhLCIi4jGFsYiIiMcUxiIiIh5TGIuIiHhMYSwiIuIxhbGIiIjHFMYiIiIeUxiLiIh4TGEsIiLisT6FsTHmVGPMEmPMMmPMdVsY5jxjzEJjzIfGmMcyW6aIiMi+K7CtAYwxfuBe4GSgGnjHGDPdWruw1zCjgB8CR1lrm40x/XdVwSIiIvuavmwZHwoss9ausNYmgMeBszYa5hLgXmttM4C1ti6zZYqIiOy7+hLGA4HVvZ5Xd3frbX9gf2PMa8aYN40xp2aqQBERkX3dNndTb8d4RgFTgEHAbGPMeGttS++BjDGXApcClJWVMWvWrAxNHjo6OjI6vk8rtWNmqB0zQ+2YGWrHzNiV7diXMK4BBvd6Pqi7W2/VwFvW2iTwsTFmKelwfqf3QNba+4D7ACZPnmynTJmyg2VvatasWWRyfJ9WasfMUDtmhtoxM9SOmbEr27Evu6nfAUYZY4YbY0LAF4DpGw3zD9JbxRhj+pHebb0ic2WKiIjsu7YZxtbaFHA58AKwCHjSWvuhMeZmY8yZ3YO9ADQaYxYCM4HvWWsbd1XRIiIi+5I+HTO21j4HPLdRtxt7/W+Ba7ofIiIish10BS4RERGPKYxFREQ8pjAWERHxmMJYRETEYwpjERERjymMRUREPKYwFhER8ZjCWERExGMKYxEREY8pjEVERDymMBYREfGYwlhERMRjCmMRERGPKYxFREQ8pjAWERHxmMJYRETEYwpjERERjymMRUREPKYwFhER8ZjCWERExGMKYxEREY8pjEVERDymMBYREfGYwlhERMRjCmMRERGPKYxFREQ8pjAWERHxmMJYRETEYwpjERERjymMRUREPKYwFhER8ZjCWERExGP7RBhXNUaZUZXEda3XpYiIiGy3fSKM3/y4kUcWJvi4sdPrUkRERLbbPhHG4wcWALCgptXjSkRERLbfPhHGI/vnEvDB/GqFsYiI7H32iTAO+n0MyfOxYI3CWERE9j77RBgDDMv38WFNm07iEhGRvc4+E8ZD8320x1NUNUW9LkVERGS77DNhPKwg/Vbm6yQuERHZy+wzYTww10fI79MZ1SIistfZZ8I44DOMLs/TSVwiIrLX2WfCGGDcwAIW1LRhrU7iEhGRvcc+Fsb5tHYlqW7u8roUERGRPtunwnj9lbh0EpeIiOxN+hTGxphTjTFLjDHLjDHXbWW4zxtjrDFmcuZK7LvR5XkEfEYncYmIyF5lm2FsjPED9wKnAQcAFxhjDtjMcHnAd4C3Ml1kX4UDfvYvy9sjt4wXNCzgspcvozOpm1mIiMiG+rJlfCiwzFq7wlqbAB4HztrMcLcAvwBiGaxvu40fWMCCmtY97iSuRxc9yms1r/Hvj//tdSkiIrKH6UsYDwRW93pe3d2thzHmYGCwtfbZDNa2Q8YNzKc5mmRN65bXCaLJKFe8cgVz6+bulppiqRgzq2YC8PTSp3fLNEVEZO8R2NkRGGN8wF3ARX0Y9lLgUoCysjJmzZq1s5Pv0dHRwaxZs0i0OAA8/sJrTCrb/Nt7pfUVZrXMorq+mu+UfydjNWzJ3M65RFNRxmeNZ37jfB598VEGhQbt8unuiPXtuLssiy0jYRMckLXJkY+92u5ux32V2jEz1I6ZsSvbsS9hXAMM7vV8UHe39fKAccAsYwxAOTDdGHOmtXZO7xFZa+8D7gOYPHmynTJlyo5X3ktdtI7bXriNXx77Sw53fPzs7RegaDBTpozeZNiuVBc/efonZAWyWBZfRvHYYg4sPTAjdWzJ9FnTKeko4Z4z7+Hkv53MqvxVfPnwL+/Sae6oWbNmkanPZVviTpyfPv1TulJdvHjii+SH8nfLdHeH3dmO+zK1Y2aoHTNjV7ZjX3ZTvwOMMsYMN8aEgC8A09f3tNa2Wmv7WWuHWWuHAW8CmwTxrvRqzavMaJvBVTOvwpoEo/rnbvEkrqeWPkVTrIm7ptxFXiiPhz98eJfW1pnsZHb1bD4z7DMUR4o5aehJPLviWbpS+i30Mx89Q0NXA53JTp5c8qTX5Ugv6zrXceNrN7K2Y63XpXjq9TWv88qqV7wuQz4FthnG1toUcDnwArAIeNJa+6Ex5mZjzJm7usC+OGfUOZxffD7/rf4vl710GaMrgps9iSuWivHgggc5rPwwjh54NF8Y/QVeXvUyK1tX7rLaZq6eSdyJc9rw0wA4d/9zaU+289Kql3bZNPcGSTfJQwseYkLpBI6sOJJHFz5K3Il7XZYArnW54bUbeGbZM/zs7Z95XY4nGrsa+f5/vs83XvoG1/7nWpY0LfG6JNnH9el3xtba56y1+1tr97PW3tbd7UZr7fTNDDtld24Vr3d03tHccewdzKufx3zn5zR2NfHPuWuIJZ2eYZ7+6Gkauhr4xoRvAPDFMV8k6Avy54V/3mV1Pf/x85TnlDOhdAIAk8smMzR/6Kf+RK5nVzzLms41XHrgpXxt3NdojDUyffkms5N44IklT/Dm2jeZ2H8is1bP4j+r/+N1SbuNtZZ/LvsnZ/3zLF6qeolLxl9CQbiAW968Bde6XpcnO6E+Wk80uefeYnefugLXqcNP5e4T76bNWUPeiD9y7fS/M+mWl7jy/97nX/OruH/en5hUNolDyg8BoF9WP84aeRbTl02noash4/W0xlt5bc1rnDL0FHwm3dTGGM4ZdQ7v1b3HipYVGZ/m3sBxHf40/09UFldyzMBjOLT8UMaWjOXhBQ/juM62R7CHe3rp09y+5vY9emvqzbVv8rv3fkdrfMPDOavaVnHXnLs4quIo/vSZPzGiYAQ/f/vnxFKe/mJxt0g4Ca6ZdQ03vHYDw/OH89QZT3HlwVdy7eRr+aD+A/7+0d+9LlF20EurXuJ/nvkfLnj2gl2yrM+EfSqMAY4eeDT3f+Z++uVB9rD7KN//MWav/ICrn72fxlg9786dzDn/+xo/eGoe//d2FScMmErSTfLYoscyXssrVa+QclM9u6jXO3O/MwmYAE9/lLmt45WtK7n97dt5eMHDe/wa/EtVL7GybSUXj78YYwzGGL427mtUtVfxctXLnta2qHERFz53IVfPvJq2RNt2v/7/Lf9//PSNn7ImuYZpL0xjXv28XVDljlvStITLXr6MS168hPvn3885/zyH12teByDlprj+1esJ+UP89MifEvQHuf6w66npqOGhBQ95XPmuFXfiXDXzKl6ueplrJl3Dn0/7M/sV7gfAGSPOYHLZZH797q9p7Gr0uFLZHq51+f3c33PNrGsYlj+MtZ1r+foLX98jA3mnf9q0J5rYfyLPnvMsjy16jD8t+BNuxVwKfGFKQmM4ZPRxLKvv4MWFtTwxJ/3z6YKh43lo/l8Z4v8fzhg/Ar/PbDA+ay3za1pZ09JFOOAnHPARDvooyAoxuDiLcMC/2Tr+/fG/GZw3mANKNvzZTr+sfhw/5HimL5/OZ0d8lsqiSvy+zY9ja6y1vFP7Do8sfIT/VP8Hn/HhWpf3697nZ8f8jJxgzgbDJ90k0WSUgnDBdk+rrxJOgoAv0LMnYHM13z/vfoblD+OkISf1dD9xyIkMzR/Kgwse5DNDP4MxhnWd67hv3n2sal/FFROv6NnVvyt0pbr437n/y18W/gU/OSTtfBY1LuHuE3/LqKJRfRrHK6te4cev/ZhDyg/hZN/JPNL+CBe/eDH3nHAPhw44dINhrbU0xZpY27mWNR1rWBddR24wl7LsMkqzS+mf3X+7PqdYKkZHsqPnucGQdJO0xltpS7TRlmhj1upZ/HPZP8kN5fLdyd9lQukEfvL6T/jGy9/gC6O/QH44n3n18/jFMb+gLKcMgMMGHMZpw07jgfkPcPp+pzM4b/AWKth7xVIxrpp1Fa/VvMaNR9zI1P2nbtDfGMMNh9/AudPP5a537+K2o2/b6vistXT/skT6oLq9mr8u+isfNn7IoeWHcvyQ4zmg+ACMMcRSMV6teZUXV73IwsaFTN1/Kl8a8yUCvm1HVzQZ5YbXbuClVS9x5n5ncuMRNzKvfh7ffuXbXPzCxTxwygP0y+q3G95h3xivrlQ1efJkO2dO5g4tb+mU89Z4Kw8ueJB/LPsHvzzulz27qK21LK/v5O2Pm3hp+dvMSf6UZMvBFHd9kYuOHMn5k4fQlXR45v0annhvAbXBx/EFW3G6BuN0DcHpGgw2gD9rNQWFawlmV2P8cXLsfkRSIyFZyqrIbZTZzzI6fB75kSA5IT9JxyWecqlNLOK9xM+xOIRMDoOyxjE8dyxtsQT10RZaYi10JDsoDg7n0LKjmTJsPBOHFBH0+1jSuIoXVz3Pq2tfZG3XSnIDhRxTfhbHlJ3B+00zefrjPzAgZzA/nPQLRhQMoyVZx/Or/sG/Pn6GplgTpVlljCwYzZDc/anI2o/SyECKQuUYgrw/dy4HTTgInw/8xhAM+CjNDVOWHyEU2PKOlJWtK3now4eYvnw6g/MGc+EBF3LGiDOIBCIbfk6rZ3HFjCu47ejbOHO/Dc//+9vSv3HzGzfzy+N+yYcNH/LY4sdwrENBqIDmeDMXjrmQyydevsk4t8a1Lo1djRRHije7wpN0ksyuns2dc+6kpqOGcNeRNK0+CX+knnDFowQDCX502E2cW3n6VqfzWs1rXD7jcg4oOYD7T76ft197m7GHjuXSly6lqq2KW466hXAgzHvrPuC92rl81LKYuLv1M+qH5Q/j+MHHc9zg45hQOgG/8VPdUc3ipsUsblpMVVsVazrWUNNRQ2Ns21tsQV+QL1Z+kUsOvKQn6GOpGL9977c8uuhRAE4Zdgp3HnvnBmGyrnMdZ/7jTA4tP5S7T7x7k/Gm3BQfNX/Eh40fEvaH2a9wP4blDyM7mI1rXVa2rWR+/XzmN8ynKdaEz/jwGR9+4ycvlMfQ/KEMzx/O8ILhFGcV0xJroSXeQlOsibfnvs1hEw8jN5hLbjCX7GA2BoMlvdxKukmq2qpY2baSla0rWdOxhkF5gxjXbxzj+o1jSN4QmuPNzK2by9y6ucxrmEdBqICJ/SdyUP+DGFE4gu/O+i5vrn2Tnx75U84edfYW2++37/2WB+Y/wIOnPNizHFmvoauBF1e+yPMrn2d+/XyG5g+lsqSSMcVjGJY/jDWda/io+SOWtSyjqq2KkUUjOWLAERxRcQSVxZVbXHnNlN7LR8d1aIm3UBgu3KGNgL5oijXR2NVIwkkQd+LEnTjGGPJD+eSH8ikIF7C8ZTmPLHyEV6pewYePUUWjWNK8BNe69M/uz+ii0cxZN4euVBeF4UKG5A1hXsM89i/anxsOv4GJ/ScCsLptNc+vfJ5Zq2f17M1yrUtHsoPmWDPXTLqGr479as88/U7tO3z7lW9TkVPB3SfcTWl2KWF/GGMMrnWp7axlResKPm79mPZEO9866FubbccdYYx511q72Xs37PNh3Fe/fvc3PLjgT4TdQTR9fB5Bt5yk42JyFpE36GmML8nIgkpWtC0h4W54/MzgJ+QMwnVCpIKrsCbR029Q9MfEo/1p60oRTaQI+n2EAz5CAR8m0E6bXUQ8uBR/9nJ8oab0i6yfALkETZgu6gBwE0WkOkfhD6/Dn70KACc6lGTLZJJtB4EN9kzTn72cyMDHMCaFEx2OPzd97NLpqMTpGoovXIsvUoMv1IAx6c/fWoNNFuKmCjAmBb4ExpcAHKyTg03lETIF5AYKyQ8VUxwupjSnmMKsCHNbnmd59A18BOjH4XRSRSerCJLHIP9JZPsL6WQ17W4VLalVZPkLOL/8HoL+IH6fIZFyaY4maOzs5L+xq0mZNsBwYMEJfPWASxlRXMr/fvBbXqr+JyXhgZzc/1IG5JSREwmQGw4QDkJbopWWWCst8RZa4s3UxapZE13Jms4q4k6cglABhw44lMPKD2NS2SSWtS5jRtUM/lv9XzqSHRQFB1K74nT6+cfwmy9MpCw/zC9efptZTb/Cn72KIl8loYAfny+FMSmMMQRMBD8RcMOs6nqH/EAFJxb+hLAvl49XraKw3wAaos3Md+6ky7equ539uLEKnK7BuIkS3GQRNlmEm8rH+OIU5EUpzO0iK7uNTt9CWuxiLA5Bkws4JG06wH34KQyVYVLFtHXk0dGRh3WzwBowFgPkhMP0yyqgLLeEQfnFVOQOIJXMoi2Woq0rSWcihbVggVa7kCbzBlNKv86Eigoqy/MY3i8Hv88QT7n8+cM/c88Hv2ZgzmCKIyUUR4rIDxdQ3bGKRY2LiDmbHlOuyKmgPdlOe6IdgIg/m7xAP1zrknIdXOsSc9t63tPOivizKc0qoy66hribPjM/O5BNNJU+aSfoCzKmeAzN8WZWt39yUUGD4ZajbuGskZu7yu8nulJdnP3Ps2lLtDE4bzB5wTxyQ7m0Jdp4d927uNZlZOFIDh9wONXt1SxsWkhdtK7n9fmhfEYVjWJg7kAWNS3io+aPACgMF9Ivqx8BX4CACRDwBbBYXOviWAfHdQj7w+QEc8gNpVdKIoFIevju1yScBPVd9elHtJ6Ek6A8p5yK3AoqciuoraqFEljWsowVLSuIOTH8xk9pdinl2eWU5ZSRHcgmEoikH/7Ihlv3FiwWxzpYm66tZ6XK58dv/NRF63rG3xxv7tNnlhfK47z9z+OCygsoyymjOdbM7OrZzFw9k4+aP+LwAYdz8rCTmVw2Gb/xM6NqBre/czu1nbV8ZuhnWNOxhgWNCwA4sPRABuQMwJA+9OU3fs4YcQZHDjxyk+m+U/sO33r5Wz3zbcAXIDeYSywV22BeLs0q5eWpL/esLCmM+yATP8aeXT2bG169gWiyizHhLxMzNSyO/pvRRaO549g7GFE4gpSbYnnLcj6o/4CEk2Bcv3GMKRlD2B8G0mvqixsX817de1hruWjcRducruta2mJJqlsbGFiYT2Ekp+eLsK5zHa9UzeLfy2ewoGkOhcEBHFR8AkeVn8TwwsGE/D5ca3seSccSSzqs7VzLX5bfSmN8LQcWnMyY3FOImH5YCzkhP9nhAH5/nJbUapoSa2iM1VAfr6G6aRXF+SWEfBFCvgjgpynWTHOskY5UMzG3BWtSG9RvnTBO65HkxY+nMFyMMdDlW0pnZAaJ8ILuNxnBxgfgxAYQb56MG6/YYBx54QCFOUGCefPo8M+nde3RxLv6bzCMP3sZkQFP4wtt/YueXrEowk2U4sZLcZOF+CNrCeYuh0DLJ+OzeeSkDoToOGrWDObUsYO4/fPjKcwO9QyzqLaJa1/6BTWxBSRTfqwbwNoABsAXx3Q/rJNPqvbL4OR2F+FSlBOmICtIbpaDm7WAipyBjC4ew6CCfErzwjjWEk+6xFMOXQmH+vY4a9tirGuNUdsWoyvpkHCjxPyLSIQXkkj6cGIVOLEK3HgZ2CAFWUGOGFHCkSNLGFiYRUs0SUtXkpZogrq2OKubo6xujrKmJYbjpr/reZEABVlBckIB1i9vjTHEkw6rmqI9wxkDnyweHEIls/CF6zCBDoy/AxOIQrKIiDucQt9+lEf2JytkiZu1dJk1RO0aEskgbS0VNDSU4yZK2fQ0FYsJtOML1adXDv2d6ZU/Jwefm0PYhCCQImm7SNmu7hXE3i/34XZ/1jaVDxjAwRdehz+rGl94LTZVgIkNJ5AaTNAfJj8SJD+3i2B2FU5wFf1DYyj1T8R1098hnzGEg5+sNEcCfrJCfrJDAZpTy3mz8RmiqQ5iTicxpxOf8XNA4eFMKjmeofn7EfQbDAafgfZkC7XR1eQG+uNzCuhMOHTG0yvlCdtCTfwDqqLziTmdWBxcHFybwu/zEQoEiPgDhAMBulJxWmLttCc66Eh2kHTjWFK41iFlUwR9QUqzSinNLqU0q5SAL8jajrWs7VxDXbQOF5fSrP6MLNyPkUUjqcipoCnWRG1nLbXR2vSZxqkosVSsZ0t2cwzpkEt/cuDYT5YFecE89ivcr+fRP7s/EX+EkD9E2B/GsU76kEk8fdgkN5jLacNPIzuYvdXv88aiySh/mPcHHl34KCMLR3La8NM4ZdgpVORWbPvFvXzU/BHvrXuP9mQ7nclOOhIdBP1BRhSMYHhB956aSPEGr1EY90GmroxSF63j+v9ez1u16ZtPXXjAhVx18FWE/KFtvHLX25FjUdv7mm21o7WWzmQnzbFm6rsaqW1v4pDyg+mXU7DZ6dR01GCtZWDuwJ7+6TVrSLkurgt+n9lkF3jKcalqirJ0XQcNHXGKc0IUZYfICqf4qO19OhMJogmHaCJFPGnJCeaTHyogP1RAXjAfa/3EUy7xpEtX0klveXfEqelczZrYQgJOKXlmFAGfH7/PcOrYcs4/ZPBW28pxLc3dIdeVdCjICvY8Nq5/V1ypx3UtTdEE9e1x6trjlOSEOGBAPj7ftj/flOPSmXDIDQc2OSeit1jSYXl9B0tq2/m4oROfSX8264PJ2nQ7OK4l6bq0RpPUd8Rp6EjQ0B4nmkiRSKUPxSRSLiW5IcYOLGBcRQFjK/IZUpxNdshPJOQnK+jHtZbWriSt0STN0SRJx6U0L0xpbnpFZvbs//S0o7WWWNKlsTNOY0eCxs44TZ1JDODzga/7s0ukXGIpl3jSIZZ0SKRcEo4l6aRraoslaepM9Iwj5aS/I/7uQzOOtT3vIZZ0cPese85sYv08GOt+v7GkS8LpfRKnA74kfrIozglRkhMiPytIPOnQmXCIxlPEUy5ZIT+54QD5kSBZYUPKsXQl0yuKsaRDe9yhM+bQ1evnoiG/j7wsPwVZPiLBEAGfD58x+H3dj+7/fb70yonjWqwFtzt3An4fQZ8h4E9/du2xFG2xJO2xFNGEQ8ifPj8nEvATDvrICQXIDvnJCQeIBA2RYCA9f/p9BP0+kq7t+dzjKZeA35AVTM9rkZAfvzFY0tO3tnte6R6+K+mQcjb8sLNCfm47e3zP810ZxvvkCVw7o392f/548h95+qOnGZI/hMMHHO51ST125KSQTJ9IYoxJ7yoL5TI4fzCUbX34gbkDN+mW3oXEVo9XBfw+RpTmMqI0d5N+B3Hqdtf9ifHAZ3folX6foV9umH654Z2Y/o7z9Zr+mAHb99qA30dB1raPS0aCfsZWFDC2Yted5Lex/nl++udt+zwAYwxZIT+DQtkMKtq+ramdkUi5PaHU1R3uPkN3wKS/X+uDPp5ySTpueve/TR/Zthayw37ywgFywukwcVzbE/axpJtewbEWx3VJOpZoIkVLNElrV5KWaJJw0Ef/vAj988L0zw+Tciyrm9J7PVY3ddEeSxIJ+nse61eegn5DwOfjo2XLKB4wmMaOBA0dCdpiSQqzQwwsSm/xhwI+YgmH9niK9liSpo4UoYCP7GCQ4uww4WC6/rxIgNxwkNxIgETKTa9IdSVp7UoQT7rd7+GTR8p1iacsTnd7rA9qX/del86EQ8pxe0IwLxKgf16E/UrT7ZRIWWIppztgXaKJFA0dcToTKaJxp2elr/fKR3pvho9IMN3OXd1Bu6XtznDAR1b3yuH6lYL1csPBzb9oF1AYb4bf5+e80ed5XYaI7AFC3cFWkLX7Fsx9MW5g31eYZqVWMWVK5S6sxlu2+xBdoHsrfHP946n0So/PGIxJH4YJ+nx92rO0OyiMRURkr2aMIRTYcqgaY4gEd82Z45myz130Q0REZG+jMBYREfGYwlhERMRjCmMRERGPKYxFREQ8pjAWERHxmMJYRETEYwpjERERjymMRUREPKYwFhER8ZjCWERExGMKYxEREY8pjEVERDymMBYREfGYwlhERMRjCmMRERGPKYxFREQ8pjAWERHxmMJYRETEYwpjERERjymMRUREPKYwFhER8ZjCWERExGMKYxEREY8FvC6gt2QySXV1NbFYbLtfW1BQwKJFi3ZBVZ8uvdsxEokwaNAggsGgx1WJiOzb9qgwrq6uJi8vj2HDhmGM2a7Xtre3k5eXt4sq+/RY347WWhobG6murmb48OFelyUisk/bo3ZTx2IxSkpKtjuIJfOMMZSUlOzQXgoREdk+e1QYAwriPYg+CxGR3WOPC2Ov5ebmel2CiIh8yiiMRUREPKYw3gJrLd/73vcYN24c48eP54knngBg7dq1HHvssRx00EGMGzeO//73vziOw0UXXdQz7K9//WuPqxcRkb3JHnU2dW8//X8fsnBNW5+HdxwHv9+/1WEOqMjnJ2eM7dP4/v73vzN37lw++OADGhoaOOSQQzj22GN57LHHOOWUU/jRj36E4zhEo1Hmzp1LTU0NCxYsAKClpaXPdYuIiGjLeAteffVVLrjgAvx+P2VlZRx33HG88847HHLIITz00EPcdNNNzJ8/n7y8PEaMGMGKFSu44ooreP7558nPz/e6fBER2YvssVvGfd2CXW93/c742GOPZfbs2Tz77LNcdNFFXHPNNXzlK1/hgw8+4IUXXuAPf/gDTz75JA8++OAur0VERPYN2jLegmOOOYYnnngCx3Gor69n9uzZHHrooaxatYqysjIuueQSLr74Yt577z0aGhpwXZfPf/7z3Hrrrbz33ntely8iInuRPXbL2Gtnn302b7zxBhMmTMAYwx133EF5eTl//vOfufPOOwkGg+Tm5vLII49QU1PDtGnTcF0XgJ///OceVy8iInuTPoWxMeZU4LeAH3jAWnv7Rv2vAS4GUkA98DVr7aoM17pbdHR0AOkLXtx5553ceeedG/T/6le/yle/+tVNXqetYRER2VHb3E1tjPED9wKnAQcAFxhjDthosPeBydbaA4GngDsyXaiIiMi+qi/HjA8FlllrV1hrE8DjwFm9B7DWzrTWRrufvgkMymyZIiIi+66+7KYeCKzu9bwaOGwrw38d+PfmehhjLgUuBSgrK2PWrFkb9C8oKKC9vb0PJW3KcZwdfq18YuN2jMVim3xOsm0dHR1qtwxQO2aG2jEzdmU7ZvQELmPMl4HJwHGb62+tvQ+4D2Dy5Ml2ypQpG/RftGjRDv88SbdQzIyN2zESiTBx4kQPK9o7zZo1i43nb9l+asfMUDtmxq5sx76EcQ0wuNfzQd3dNmCMOQn4EXCctTaemfJERET2fX05ZvwOMMoYM9wYEwK+AEzvPYAxZiLwR+BMa21d5ssUERHZd20zjK21KeBy4AVgEfCktfZDY8zNxpgzuwe7E8gF/maMmWuMmb6F0YmIiMhG+nTM2Fr7HPDcRt1u7PX/SRmua5+XSqUIBHTNFRER0eUwN+tzn/sckyZNYuzYsdx3330APP/88xx88MFMmDCBE088EUifWTdt2jTGjx/PgQceyNNPPw1Abm5uz7ieeuopLrroIgAuuugiLrvsMg477DC+//3v8/bbb3PEEUcwceJEjjzySJYsWQKkz2j+7ne/y7hx4zjwwAO5++67mTFjBp/73Od6xvvSSy9x9tln74bWEBGRXW3P3TT793VQO7/Pg2c5KfBv4+2Uj4fTbt/6MMCDDz5IcXExXV1dHHLIIZx11llccsklzJ49m+HDh9PU1ATALbfcQkFBAfPnp+tsbm7e5rirq6t5/fXX8fv9tLW18d///pdAIMDLL7/M9ddfz9NPP819993HypUrmTt3LoFAgKamJoqKivjWt75FfX09paWlPPTQQ3zta1/bdsOIiMgeb88NYw/97ne/45lnngFg9erV3HfffRx77LEMHz4cgOLiYgBefvllHn/88Z7XFRUVbXPcU6dO7bnvcmtrK1/96lf56KOPMMaQTCZ7xnvZZZf17MZeP70LL7yQRx99lGnTpvHGG2/wyCOPZOgdi4iIl/bcMO7DFmxvXRn6nfGsWbN4+eWXeeONN8jOzmbKlCkcdNBBLF68uM/jMMb0/B+LxTbol5OT0/P/j3/8Y44//nieeeYZVq5cuc3fr02bNo0zzjiDSCTC1KlTdcxZRGQfoWPGG2ltbaWoqIjs7GwWL17Mm2++SSwWY/bs2Xz88ccAPbupTz75ZO69996e167fTV1WVsaiRYtwXbdnC3tL0xo4cCAADz/8cE/3k08+mT/+8Y+kUqkNpldRUUFFRQW33nor06ZNy9ybFhERTymMN3LqqaeSSqUYM2YM1113HYcffjilpaXcd999nHPOOUyYMIHzzz8fgBtuuIHm5mbGjRvHhAkTmDlzJgC33347p59+OkceeSQDBgzY4rS+//3v88Mf/pCJEyf2BC/AxRdfzJAhQzjwwAOZMGECjz32WE+/L33pSwwePJgxY8bsohYQEZHdzVhrPZnw5MmT7Zw5czbotmjRoh0OmU/L5TAvv/xyJk6cyNe//vVdMv6N23FnPpNPM11+MDPUjpmhdsyMnW1HY8y71trJm+ung457kUmTJpGTk8OvfvUrr0sREZEMUhjvRd59912vSxARkV1Ax4xFREQ8pjAWERHxmMJYRETEYwpjERERjymMRUREPKYw3gm97860sZUrVzJu3LjdWI2IiOytFMYiIiIe22N/Z/yLt3/B4qa+35zBcZyeuyFtSWVxJT849Adb7H/dddcxePBgvv3tbwNw0003EQgEmDlzJs3NzSSTSW699VbOOuusPtcF6ZtFfPOb32TOnDkEAgHuuusujj/+eD788EOmTZtGIpHAdV2efvppKioqOO+886iursZxHH784x/3XH5TRET2TXtsGHvh/PPP56qrruoJ4yeffJIXXniBK6+8kvz8fBoaGjj88MM588wzN7gz07bce++9GGOYP38+ixcv5jOf+QxLly7lD3/4A9/5znf40pe+RCKRwHEcnnvuOSoqKnj22WeB9M0kRERk37bHhvHWtmA3JxPXpp44cSJ1dXWsWbOG+vp6ioqKKC8v5+qrr2b27Nn4fD5qampYt24d5eXlfR7vq6++yhVXXAFAZWUlQ4cOZenSpRxxxBHcdtttVFdXc8455zBq1CjGjx/Ptddeyw9+8ANOP/10jjnmmJ16TyIisufTMeONTJ06laeeeoonnniC888/n7/+9a/U19fz7rvvMnfuXMrKyja5R/GO+uIXv8j06dPJysris5/9LDNmzGD//ffnvffeY/z48dxwww3cfPPNGZmWiIjsufbYLWOvnH/++VxyySU0NDTwn//8hyeffJL+/fsTDAaZOXMmq1at2u5xHnPMMfz1r3/lhBNOYOnSpVRVVTF69GhWrFjBiBEjuPLKK6mqqmLevHlUVlZSXFzMl7/8ZQoLC3nggQd2wbsUEZE9icJ4I2PHjqW9vZ2BAwcyYMAAvvSlL3HGGWcwfvx4Jk+eTGVl5XaP81vf+hbf/OY3GT9+PIFAgIcffphwOMyTTz7JX/7yF4LBIOXl5Vx//fW88847fO9738Pn8xEMBvn973+/C96liIjsSRTGmzF//vye//v168cbb7yx2eE6Ojq2OI5hw4axYMECACKRCA899NAmw1x33XVcd911G3Q75ZRTOOWUU3akbBER2UvpmLGIiIjHtGW8k+bPn8+FF164QbdwOMxbb73lUUUiIrK3URjvpPHjxzN37lyvyxARkb2YdlOLiIh4TGEsIiLiMYWxiIiIxxTGIiIiHlMY74St3c9YRESkrxTG+4BUKuV1CSIishP22J821f7sZ8QX9f1+xinHoWkb9zMOj6mk/Prrt9g/k/cz7ujo4Kyzztrs6x555BF++ctfYozhwAMP5C9/+Qvr1q3jsssuY8WKFQD8/ve/p6KigtNPP73nSl6//OUv6ejo4KabbmLKlCkcdNBBvPrqq1xwwQXsv//+3HrrrSQSCUpKSvjrX/9KWVkZHR0dXHHFFcyZMwdjDD/5yU9obW1l3rx5/OY3vwHg/vvvZ+HChfz617/e5vsSEZHM22PD2AuZvJ9xJBLhmWee2eR1Cxcu5NZbb+X111+nX79+NDU1AXDllVdy3HHH8cwzz+A4Dh0dHTQ3N291GolEgjlz5gDQ3NzMm2++iTGGBx54gDvuuINf/epX3HLLLRQUFPRc4rO5uZlgMMhtt93GnXfeSTAY5KGHHuKPf/zjzjafiIjsoD02jLe2Bbs5e9r9jK21XH/99Zu8bsaMGUydOpV+/foBUFxcDMCMGTN45JFHAPD7/RQUFGwzjM8///ye/6urqzn//PNZu3YtiUSC4cOHA/Dyyy/z+OOP9wxXVFQEwAknnMC//vUvxowZQzKZZPz48dvZWiIikil7bBh7Zf39jGtraze5n3EwGGTYsGF9up/xjr6ut0AggOu6Pc83fn1OTk7P/1dccQXXXHMNZ555JrNmzeKmm27a6rgvvvhifvazn1FZWcm0adO2qy4REcksncC1kfPPP5/HH3+cp556iqlTp9La2rpD9zPe0utOOOEE/va3v9HY2AjQs5v6xBNP7LldouM4tLa2UlZWRl1dHY2NjcTjcf71r39tdXoDBw4E4M9//nNP95NPPpl777235/n6re3DDjuM1atX89hjj3HBBRf0tXlERGQXUBhvZHP3M54zZw7jx4/nkUce6fP9jLf0urFjx/KjH/2I4447jgkTJnDNNdcA8Nvf/paZM2cyfvx4Jk2axMKFCwkGg9x4440ceuihnHzyyVud9k033cTUqVOZNGlSzy5wgBtuuIHm5mbGjRvHhAkTmDlzZk+/8847j6OOOqpn17WIiHjDWGs9mfDkyZPt+pOP1lu0aBFjxozZofFl4pjxp83pp5/O1VdfzYknntjTbeN23JnP5NNs1qxZTJkyxesy9npqx8xQO2bGzrajMeZda+3kzfXTlvGnUEtLC/vvvz9ZWVkbBLGIiHhDJ3DtpL3xfsaFhYUsXbrU6zJERKSbwngn6X7GIiKys/a43dReHcOWTemzEBHZPfaoMI5EIjQ2NioE9gDWWhobG4lEIl6XIiKyz9ujdlMPGjSI6upq6uvrt/u1sVhMwZEBvdsxEokwaNAgjysSEdn39SmMjTGnAr8F/MAD1trbN+ofBh4BJgGNwPnW2pXbW0wwGOy5jOP2mjVrFhMnTtyh18on1I4iIrvfNndTG2P8wL3AacABwAXGmAM2GuzrQLO1diTwa+AXmS5URERkX9WXY8aHAsustSustQngcWDjewieBay/BuNTwIlmW7c1EhEREaBvYTwQWN3reXV3t80OY61NAa1ASSYKFBER2dft1hO4jDGXApd2P+0wxizJ4Oj7AQ0ZHN+nldoxM9SOmaF2zAy1Y2bsbDsO3VKPvoRxDTC41/NB3d02N0y1MSYAFJA+kWsD1tr7gPv6MM3tZoyZs6VrfkrfqR0zQ+2YGWrHzFA7ZsaubMe+7KZ+BxhljBlujAkBXwCmbzTMdOCr3f+fC8yw+rGwiIhIn2xzy9hamzLGXA68QPqnTQ9aaz80xtwMzLHWTgf+BPzFGLMMaCId2CIiItIHfTpmbK19Dnhuo2439vo/BkzNbGnbbZfs/v4UUjtmhtoxM9SOmaF2zIxd1o6e3c9YRERE0vaoa1OLiIh8Gu0TYWyMOdUYs8QYs8wYc53X9ewtjDGDjTEzjTELjTEfGmO+09292BjzkjHmo+6/RV7XujcwxviNMe8bY/7V/Xy4Meat7vnyie4TIGUrjDGFxpinjDGLjTGLjDFHaH7cfsaYq7u/0wuMMf9njIloftw2Y8yDxpg6Y8yCXt02O/+ZtN91t+c8Y8zBOzPtvT6M+3i5Ttm8FHCttfYA4HDg291tdx3wirV2FPBK93PZtu8Ai3o9/wXw6+7LxDaTvmysbN1vgeettZXABNLtqflxOxhjBgJXApOtteNIn3j7BTQ/9sXDwKkbddvS/HcaMKr7cSnw+52Z8F4fxvTtcp2yGdbatdba97r/bye94BvIhpc3/TPwOU8K3IsYYwYB/wM80P3cACeQvjwsqB23yRhTABxL+tcZWGsT1toWND/uiACQ1X3dh2xgLZoft8laO5v0L4J629L8dxbwiE17Eyg0xgzY0WnvC2Hcl8t1yjYYY4YBE4G3gDJr7druXrVAmVd17UV+A3wfcLuflwAt3ZeHBc2XfTEcqAce6t7d/4AxJgfNj9vFWlsD/BKoIh3CrcC7aH7cUVua/zKaPftCGMtOMsbkAk8DV1lr23r36754i0653wpjzOlAnbX2Xa9r2csFgIOB31trJwKdbLRLWvPjtnUf0zyL9MpNBZDDprteZQfsyvlvXwjjvlyuU7bAGBMkHcR/tdb+vbvzuvW7W7r/1nlV317iKOBMY8xK0odJTiB97LOwezchaL7si2qg2lr7Vvfzp0iHs+bH7XMS8LG1tt5amwT+Tnoe1fy4Y7Y0/2U0e/aFMO7L5TplM7qPa/4JWGStvatXr96XN/0q8M/dXdvexFr7Q2vtIGvtMNLz3wxr7ZeAmaQvDwtqx22y1tYCq40xo7s7nQgsRPPj9qoCDjfGZHd/x9e3o+bHHbOl+W868JXus6oPB1p77c7ebvvERT+MMZ8lfcxu/eU6b/O2or2DMeZo4L/AfD451nk96ePGTwJDgFXAedbajU9qkM0wxkwBvmutPd0YM4L0lnIx8D7wZWtt3MPy9njGmINInwQXAlYA00hvNGh+3A7GmJ8C55P+xcT7wMWkj2dqftwKY8z/AVNI351pHfAT4B9sZv7rXtG5h/QhgCgwzVo7Z4envS+EsYiIyN5sX9hNLSIisldTGIuIiHhMYSwiIuIxhbGIiIjHFMYiIiIeUxiLiIh4TGEsIiLiMYWxiIiIx/4/yoCiV8SiiVUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 782us/step - loss: 0.3664 - accuracy: 0.8148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36638692021369934, 0.8148074150085449]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Wczytaj nauczony model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 768us/step - loss: 0.3568 - accuracy: 0.8242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3568456768989563, 0.8242363929748535]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"wagi_best.h5py\")\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "* Naucz dowolny model na zbiorze MNIST.\n",
    "* Zapisz optymalne parametry uczenia do pliku\n",
    "* Wczytaj dane z pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "y_valid = np_utils.to_categorical(y_valid)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1718/1719 [============================>.] - ETA: 0s - loss: 0.6198 - accuracy: 0.8404INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6196 - accuracy: 0.8405 - val_loss: 0.3103 - val_accuracy: 0.9120\n",
      "Epoch 2/30\n",
      "1702/1719 [============================>.] - ETA: 0s - loss: 0.2957 - accuracy: 0.9151INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2953 - accuracy: 0.9151 - val_loss: 0.2473 - val_accuracy: 0.9304\n",
      "Epoch 3/30\n",
      "1689/1719 [============================>.] - ETA: 0s - loss: 0.2428 - accuracy: 0.9303INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2430 - accuracy: 0.9302 - val_loss: 0.2060 - val_accuracy: 0.9426\n",
      "Epoch 4/30\n",
      "1718/1719 [============================>.] - ETA: 0s - loss: 0.2076 - accuracy: 0.9406INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2075 - accuracy: 0.9406 - val_loss: 0.1823 - val_accuracy: 0.9494\n",
      "Epoch 5/30\n",
      "1708/1719 [============================>.] - ETA: 0s - loss: 0.1810 - accuracy: 0.9486INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1811 - accuracy: 0.9485 - val_loss: 0.1645 - val_accuracy: 0.9536\n",
      "Epoch 6/30\n",
      "1686/1719 [============================>.] - ETA: 0s - loss: 0.1610 - accuracy: 0.9541INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1603 - accuracy: 0.9543 - val_loss: 0.1483 - val_accuracy: 0.9602\n",
      "Epoch 7/30\n",
      "1699/1719 [============================>.] - ETA: 0s - loss: 0.1431 - accuracy: 0.9598INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1431 - accuracy: 0.9598 - val_loss: 0.1367 - val_accuracy: 0.9634\n",
      "Epoch 8/30\n",
      "1697/1719 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.9634INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1291 - accuracy: 0.9633 - val_loss: 0.1295 - val_accuracy: 0.9636\n",
      "Epoch 9/30\n",
      "1705/1719 [============================>.] - ETA: 0s - loss: 0.1175 - accuracy: 0.9674INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1174 - accuracy: 0.9674 - val_loss: 0.1183 - val_accuracy: 0.9672\n",
      "Epoch 10/30\n",
      "1695/1719 [============================>.] - ETA: 0s - loss: 0.1079 - accuracy: 0.9697INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1077 - accuracy: 0.9696 - val_loss: 0.1090 - val_accuracy: 0.9692\n",
      "Epoch 11/30\n",
      "1706/1719 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.9720WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
      "INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0987 - accuracy: 0.9720 - val_loss: 0.1050 - val_accuracy: 0.9696\n",
      "Epoch 12/30\n",
      "1702/1719 [============================>.] - ETA: 0s - loss: 0.0903 - accuracy: 0.9746INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0911 - accuracy: 0.9744 - val_loss: 0.1004 - val_accuracy: 0.9710\n",
      "Epoch 13/30\n",
      "1702/1719 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9762INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0843 - accuracy: 0.9762 - val_loss: 0.0948 - val_accuracy: 0.9726\n",
      "Epoch 14/30\n",
      "1715/1719 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9781INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0781 - accuracy: 0.9781 - val_loss: 0.0920 - val_accuracy: 0.9738\n",
      "Epoch 15/30\n",
      "1710/1719 [============================>.] - ETA: 0s - loss: 0.0724 - accuracy: 0.9797INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0726 - accuracy: 0.9796 - val_loss: 0.0877 - val_accuracy: 0.9726\n",
      "Epoch 16/30\n",
      "1689/1719 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9806INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0677 - accuracy: 0.9806 - val_loss: 0.0860 - val_accuracy: 0.9740\n",
      "Epoch 17/30\n",
      "1699/1719 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9822INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0632 - accuracy: 0.9822 - val_loss: 0.0835 - val_accuracy: 0.9754\n",
      "Epoch 18/30\n",
      "1694/1719 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 0.9837INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0592 - accuracy: 0.9837 - val_loss: 0.0799 - val_accuracy: 0.9766\n",
      "Epoch 19/30\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 0.0555 - accuracy: 0.9850INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0555 - accuracy: 0.9850 - val_loss: 0.0782 - val_accuracy: 0.9768\n",
      "Epoch 20/30\n",
      "1711/1719 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9860INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0519 - accuracy: 0.9860 - val_loss: 0.0775 - val_accuracy: 0.9764\n",
      "Epoch 21/30\n",
      "1710/1719 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9870INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0488 - accuracy: 0.9869 - val_loss: 0.0736 - val_accuracy: 0.9784\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0458 - accuracy: 0.9878 - val_loss: 0.0744 - val_accuracy: 0.9780\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0431 - accuracy: 0.9884 - val_loss: 0.0756 - val_accuracy: 0.9770\n",
      "Epoch 24/30\n",
      "1696/1719 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9895INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0404 - accuracy: 0.9894 - val_loss: 0.0729 - val_accuracy: 0.9774\n",
      "Epoch 25/30\n",
      "1693/1719 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9900INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0383 - accuracy: 0.9900 - val_loss: 0.0708 - val_accuracy: 0.9792\n",
      "Epoch 26/30\n",
      "1691/1719 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.9910INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0680 - val_accuracy: 0.9796\n",
      "Epoch 27/30\n",
      "1710/1719 [============================>.] - ETA: 0s - loss: 0.0339 - accuracy: 0.9916INFO:tensorflow:Assets written to: wagi_best2.h5py\\assets\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0340 - accuracy: 0.9916 - val_loss: 0.0672 - val_accuracy: 0.9806\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0321 - accuracy: 0.9921 - val_loss: 0.0692 - val_accuracy: 0.9804\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0300 - accuracy: 0.9932 - val_loss: 0.0676 - val_accuracy: 0.9792\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0285 - accuracy: 0.9935 - val_loss: 0.0673 - val_accuracy: 0.9796\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "save_best_model = ModelCheckpoint(\"wagi_best2.h5py\",save_best_only=True)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "save_best_model = ModelCheckpoint(\"wagi_best2.h5py\",save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[save_best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06872598081827164, 0.9789000153541565]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"wagi_best2.h5py\")\n",
    "model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
